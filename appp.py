import streamlit as st
import feedparser
import urllib.parse
import os
import time
import requests
import urllib3
import sqlite3  # DB ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€
import pandas as pd  # ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
from datetime import datetime, timedelta, timezone
from email.utils import parsedate_to_datetime
from newspaper import Article, Config
import nltk
import google.generativeai as genai

# -------------------------------------------
# 0. API í‚¤ ë° ì´ˆê¸° ì„¤ì •
# -------------------------------------------

GOOGLE_API_KEY = "AIzaSyAdnBk6ZdKpxL98LHHaGj9Bjbfk_dX81DA" 

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
    nltk.download('punkt_tab')

HISTORY_FILE = "seen_titles.txt"
DB_FILE = "news_database.db" # DB íŒŒì¼ëª…

# -------------------------------------------
# 1. ìœ í‹¸ë¦¬í‹° ë° DB í•¨ìˆ˜ë“¤
# -------------------------------------------

# [DB ê´€ë ¨ í•¨ìˆ˜ ì¶”ê°€] 
def init_db():
    """DB í…Œì´ë¸” ì´ˆê¸°í™”"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê±´ë„ˆëœ€
    c.execute('''
        CREATE TABLE IF NOT EXISTS saved_news (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword TEXT,
            title TEXT,
            link TEXT,
            pub_date TEXT,
            saved_at TEXT
        )
    ''')
    conn.commit()
    conn.close()

def save_news_to_db(keyword, title, link, pub_date):
    """ë‰´ìŠ¤ DB ì €ì¥"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    # ì¤‘ë³µ ì²´í¬ (ì œëª©ê³¼ ë§í¬ê°€ ê°™ìœ¼ë©´ ì €ì¥ ì•ˆ í•¨)
    c.execute("SELECT id FROM saved_news WHERE title = ? AND link = ?", (title, link))
    if c.fetchone():
        conn.close()
        return False # ì´ë¯¸ ì¡´ì¬í•¨
    
    saved_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO saved_news (keyword, title, link, pub_date, saved_at) VALUES (?, ?, ?, ?, ?)",
              (keyword, title, link, pub_date, saved_at))
    conn.commit()
    conn.close()
    return True

def get_saved_news():
    """ì €ì¥ëœ ë‰´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì‹ ìˆœ)"""
    conn = sqlite3.connect(DB_FILE)
    df = pd.read_sql_query("SELECT * FROM saved_news ORDER BY saved_at DESC", conn)
    conn.close()
    return df

def delete_news_from_db(news_ids):
    """ë‰´ìŠ¤ ì‚­ì œ"""
    if not news_ids: return
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    # ë¦¬ìŠ¤íŠ¸ë¥¼ íŠœí”Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¿¼ë¦¬ ì‹¤í–‰
    placeholders = ', '.join('?' for _ in news_ids)
    c.execute(f"DELETE FROM saved_news WHERE id IN ({placeholders})", news_ids)
    conn.commit()
    conn.close()

# ì•± ì‹œì‘ ì‹œ DB ì´ˆê¸°í™” ì‹¤í–‰
init_db()

def load_seen_titles():
    if not os.path.exists(HISTORY_FILE):
        return set()
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def save_seen_title(title):
    clean_title = title.replace("\n", " ")
    with open(HISTORY_FILE, "a", encoding="utf-8") as f:
        f.write(clean_title + "\n")

def format_date_kor(date_str):
    try:
        if not date_str: return "ì‹œê°„ ì •ë³´ ì—†ìŒ"
        dt = parsedate_to_datetime(date_str)
        KST = timezone(timedelta(hours=9))
        dt_kst = dt.astimezone(KST)
        return dt_kst.strftime("%Yë…„ %mì›” %dì¼ %H:%M")
    except:
        return date_str[:16]

def get_current_time_str():
    # í˜„ì¬ ì‹œê°„ì„ í•œêµ­ ì‹œê°„(KST)ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
    KST = timezone(timedelta(hours=9))
    now = datetime.now(KST) 
    return now.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ")

def fetch_rss_feed(url):
    try:
        response = requests.get(url, timeout=10, verify=False)
        return feedparser.parse(response.content)
    except Exception as e:
        return None

# -------------------------------------------
# 2. í™”ë©´ êµ¬ì„± (UI)
# -------------------------------------------
st.set_page_config(page_title="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§", page_icon="ğŸ’»", layout="wide")

if 'selected_article_url' not in st.session_state:
    st.session_state['selected_article_url'] = None
if 'selected_article_title' not in st.session_state:
    st.session_state['selected_article_title'] = None

with st.sidebar:
    st.header("âš™ï¸ ëª¨ë‹ˆí„°ë§ ì„¤ì •")
    default_keywords = "ë¡¯ë°ë§ˆíŠ¸, ë¡¯ë°ì›°í‘¸ë“œ, [ë‹¨ë…]ë¡¯ë°, ë¡¯ë°ì¹ ì„±, ì„¸ë¸ì¼ë ˆë¸, ì‹ì•½ì²˜, ì‹ì¤‘ë…, ë¦¬ì½œ"
    user_input = st.text_area("í‚¤ì›Œë“œ ì…ë ¥ (ì½¤ë§ˆ êµ¬ë¶„)", value=default_keywords, height=100)
    
    KEYWORDS = [k.strip() for k in user_input.split(',') if k.strip()]
    
    st.divider()
    
    st.subheader("â±ï¸ ìë™ ì—…ë°ì´íŠ¸")
    auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ ì¼œê¸°", value=True)
    refresh_interval = st.slider("ì—…ë°ì´íŠ¸ ì£¼ê¸° (ë¶„)", 5, 60, 15)
    
    if st.button("ğŸ—‘ï¸ ìˆ˜ë™ ì—…ë°ì´íŠ¸"):
        if os.path.exists(HISTORY_FILE):
            os.remove(HISTORY_FILE)
            st.rerun()

st.title("ğŸ’» ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")

# -------------------------------------------
# 3. ë©”ì¸ ë¡œì§
# -------------------------------------------
# [ë³€ê²½] íƒ­ì„ 3ê°œë¡œ ëŠ˜ë¦¼
tab1, tab2, tab3 = st.tabs(["ğŸ“¢ ë‰´ìŠ¤ ëª©ë¡", "ğŸ“ AI ìƒì„¸ ìš”ì•½", "ğŸ—„ï¸ DB ì €ì¥"])

# === [íƒ­ 1] ë‰´ìŠ¤ ëª©ë¡ ===
with tab1:
    status_container = st.container()
    
    seen_titles = load_seen_titles()
    grouped_news = {k: [] for k in KEYWORDS}
    new_news_count = 0 
    
    for keyword in KEYWORDS:
        clean_keyword = keyword.strip()
        search_query = clean_keyword + " when:1h"
        encoded_keyword = urllib.parse.quote(search_query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
        
        feed = fetch_rss_feed(rss_url)
        
        if not feed or not feed.entries:
            continue

        for entry in feed.entries:
            title = entry.title
            link = entry.link
            nice_date = format_date_kor(entry.get('published', ''))
            
            if clean_keyword not in title: continue
            
            grouped_news[clean_keyword].append({
                "title": title, "link": link, "date": nice_date
            })
            
            if title not in seen_titles:
                seen_titles.add(title)
                save_seen_title(title)
                new_news_count += 1

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    current_time = get_current_time_str()
    if new_news_count > 0:
        status_container.success(f"ğŸ”¥ **ì—…ë°ì´íŠ¸ ì™„ë£Œ ({current_time})** : {new_news_count}ê±´ì˜ ìƒˆë¡œìš´ ë‰´ìŠ¤!")
        st.toast(f"{new_news_count}ê±´ì˜ ìƒˆ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤!", icon="ğŸ”¥")
    else:
        status_container.info(f"âœ… **ì—…ë°ì´íŠ¸ ì™„ë£Œ ({current_time})** : ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ë‰´ìŠ¤ ì¹´ë“œ ì¶œë ¥
    btn_idx = 0 
    for keyword, items in grouped_news.items():
        if items: 
            with st.expander(f"ğŸ“‚ **{keyword}** ({len(items)}ê±´)", expanded=True):
                for item in items:
                    with st.container():
                        # [ë³€ê²½] ë²„íŠ¼ ë°°ì¹˜ë¥¼ ìœ„í•´ ì»¬ëŸ¼ ì¡°ì • (ì €ì¥ ë²„íŠ¼ ì¶”ê°€)
                        c1, c2, c3, c4 = st.columns([1.2, 3.5, 0.8, 0.8])
                        
                        c1.markdown(f":orange[{item['date']}]")
                        c2.markdown(f"[{item['title']}]({item['link']})")
                        
                        # AI ìš”ì•½ ë²„íŠ¼
                        if c3.button("ğŸ“ ìš”ì•½", key=f"btn_sum_{btn_idx}"):
                            st.session_state['selected_article_url'] = item['link']
                            st.session_state['selected_article_title'] = item['title']
                            st.toast("íƒ­ 2ë¡œ ì´ë™í•˜ì„¸ìš”!", icon="ğŸ‘‰")
                        
                        # [ì¶”ê°€] DB ì €ì¥ ë²„íŠ¼
                        if c4.button("ğŸ’¾ ì €ì¥", key=f"btn_save_{btn_idx}"):
                            success = save_news_to_db(keyword, item['title'], item['link'], item['date'])
                            if success:
                                st.toast("ì €ì¥ì†Œ(DB)ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
                            else:
                                st.toast("ì´ë¯¸ ì €ì¥ëœ ë‰´ìŠ¤ì…ë‹ˆë‹¤.", icon="âš ï¸")
                                
                        btn_idx += 1
                    st.divider()

# === [íƒ­ 2] AI ìš”ì•½ (ìˆ˜ì •ë¨) ===
with tab2:
    st.header("ğŸ“ Gemini ê¸°ì‚¬ ìš”ì•½")
    selected_url = st.session_state['selected_article_url']
    
    if selected_url is None:
        st.info("ğŸ‘ˆ [ë‰´ìŠ¤ ëª©ë¡] íƒ­ì—ì„œ 'AI ìš”ì•½' ë²„íŠ¼ì„ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        st.subheader(f"{st.session_state['selected_article_title']}")
        st.markdown("---")
        
        with st.spinner("ğŸ”— ì‹¤ì œ ê¸°ì‚¬ ì£¼ì†Œë¥¼ ì°¾ëŠ” ì¤‘..."):
            # [ì¤‘ìš”] ì—¬ê¸°ì„œ êµ¬ê¸€ ì£¼ì†Œë¥¼ ì‹¤ì œ ì–¸ë¡ ì‚¬ ì£¼ì†Œë¡œ ë°”ê¿‰ë‹ˆë‹¤.
            final_url = get_final_url(selected_url)
        
        # ì‹¤ì œ ì£¼ì†Œë¡œ ìš”ì•½ ì‹œë„
        with st.spinner(f"Geminiê°€ ê¸°ì‚¬ë¥¼ ì½ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ({final_url})"):
            try:
                config = Config()
                config.request_timeout = 10
                # ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ í—¤ë” ì„¤ì •
                config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                config.request_kwargs = {'verify': False}
                
                # ë³€í™˜ëœ final_url ì‚¬ìš©
                article = Article(final_url, language='ko', config=config)
                article.download()
                article.parse()
                
                if article.top_image:
                    st.image(article.top_image, use_container_width=True)

                if len(article.text) < 50:
                    st.warning("âš ï¸ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë³´ì•ˆì´ ê°•í•œ ì–¸ë¡ ì‚¬ì´ê±°ë‚˜ ìœ ë£Œ ê¸°ì‚¬ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                    st.write(f"ì›ë³¸ ë§í¬: {final_url}")
                else:
                    prompt = f"""
                    ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì½ê³  ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:
                    1. **í•œì¤„ ìš”ì•½**: ê¸°ì‚¬ì˜ í•µì‹¬ ì£¼ì œ
                    2. **ìƒì„¸ í¬ì¸íŠ¸**: ì¤‘ìš” ë‚´ìš© 3ê°€ì§€ (ê¸€ë¨¸ë¦¬ ê¸°í˜¸)
                    3. **ê°ì • ë¶„ì„**: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜
                    
                    [ê¸°ì‚¬ ë³¸ë¬¸]
                    {article.text[:3000]}
                    """
                    response = model.generate_content(prompt)
                    st.success(response.text)

                with st.expander("ì›ë³¸ ë³¸ë¬¸ ë³´ê¸°"):
                    st.write(article.text)
                    
            except Exception as e:
                st.error("ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.caption(f"Error: {e}")
# === [íƒ­ 3] ì €ì¥ì†Œ (ì‹ ê·œ ê¸°ëŠ¥) ===
with tab3:
    st.header("ğŸ—„ï¸ ì €ì¥ëœ ë‰´ìŠ¤ ê´€ë¦¬")
    st.caption("ì˜êµ¬ ì €ì¥ëœ ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê±°ë‚˜ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„° ë¡œë“œ
    df = get_saved_news()
    
    if df.empty:
        st.info("ì•„ì§ ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë‰´ìŠ¤ ëª©ë¡' íƒ­ì—ì„œ 'ğŸ’¾ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    else:
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ (ì„ íƒ ì‚­ì œ ê¸°ëŠ¥ì„ ìœ„í•´ data_editor ì‚¬ìš©)
        st.subheader(f"ì´ {len(df)}ê±´ì˜ ìŠ¤í¬ë©")
        
        # ì‚­ì œë¥¼ ìœ„í•œ ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€ (UIìš©)
        df_display = df.copy()
        df_display['ì‚­ì œì„ íƒ'] = False
        
        # ì»¬ëŸ¼ ìˆœì„œ ë° ì´ë¦„ ì •ë¦¬
        df_display = df_display[['ì‚­ì œì„ íƒ', 'keyword', 'title', 'pub_date', 'saved_at', 'link', 'id']]
        
        edited_df = st.data_editor(
            df_display,
            column_config={
                "ì‚­ì œì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ì‚­ì œí•  í•­ëª© ì„ íƒ"),
                "keyword": "í‚¤ì›Œë“œ",
                "title": "ì œëª©",
                "pub_date": "ê¸°ì‚¬ ë‚ ì§œ",
                "saved_at": "ì €ì¥ ì¼ì‹œ",
                "link": st.column_config.LinkColumn("ë§í¬"),
                "id": None # IDëŠ” ìˆ¨ê¹€
            },
            hide_index=True,
            use_container_width=True
        )
        
        col1, col2 = st.columns([1, 4])
        
        with col1:
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ", type="primary"):
                # ì²´í¬ëœ í•­ëª©ì˜ ID ì¶”ì¶œ
                selected_ids = edited_df[edited_df['ì‚­ì œì„ íƒ'] == True]['id'].tolist()
                if selected_ids:
                    delete_news_from_db(selected_ids)
                    st.success(f"{len(selected_ids)}ê±´ ì‚­ì œ ì™„ë£Œ!")
                    time.sleep(1) # ì ì‹œ ëŒ€ê¸° í›„ ë¦¬ëŸ°
                    st.rerun()
                else:
                    st.warning("ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    
        with col2:
            # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€(CSV)ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"news_scrap_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )

# ìë™ ìƒˆë¡œê³ ì¹¨
if auto_refresh:
    time.sleep(refresh_interval * 60)
    st.rerun()


