import streamlit as st
import feedparser
import urllib.parse
import os
import time
import requests
import urllib3
import sqlite3
import pandas as pd
from datetime import datetime, timedelta, timezone
from email.utils import parsedate_to_datetime
from newspaper import Article, Config
import nltk
import google.generativeai as genai

# -------------------------------------------
# 0. API í‚¤ ë° ì´ˆê¸° ì„¤ì •
# -------------------------------------------

# ğŸ‘‡ [ì¤‘ìš”] API í‚¤ í™•ì¸
GOOGLE_API_KEY = "AIzaSyAdnBk6ZdKpxL98LHHaGj9Bjbfk_dX81DA" 

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
    nltk.download('punkt_tab')

HISTORY_FILE = "seen_titles.txt"
DB_FILE = "news_database.db"

# -------------------------------------------
# 1. ìœ í‹¸ë¦¬í‹° ë° DB í•¨ìˆ˜ë“¤
# -------------------------------------------

# âœ… [ëˆ„ë½ë˜ì—ˆë˜ í•¨ìˆ˜] êµ¬ê¸€ ë‹¨ì¶• URLì„ ì‹¤ì œ ë‰´ìŠ¤ ì£¼ì†Œë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜
def get_final_url(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        # allow_redirects=Trueë¡œ ìµœì¢… ëª©ì ì§€ URLì„ ê°€ì ¸ì˜´
        response = requests.get(url, headers=headers, timeout=5, allow_redirects=True, verify=False)
        return response.url
    except Exception:
        return url

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS saved_news (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            keyword TEXT,
            title TEXT,
            link TEXT,
            pub_date TEXT,
            saved_at TEXT
        )
    ''')
    conn.commit()
    conn.close()

def save_news_to_db(keyword, title, link, pub_date):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    
    # ì¤‘ë³µ ì²´í¬
    c.execute("SELECT id FROM saved_news WHERE title = ? AND link = ?", (title, link))
    if c.fetchone():
        conn.close()
        return False # ì´ë¯¸ ì¡´ì¬
    
    saved_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO saved_news (keyword, title, link, pub_date, saved_at) VALUES (?, ?, ?, ?, ?)",
              (keyword, title, link, pub_date, saved_at))
    conn.commit()
    conn.close()
    return True

def get_saved_news():
    conn = sqlite3.connect(DB_FILE)
    df = pd.read_sql_query("SELECT * FROM saved_news ORDER BY saved_at DESC", conn)
    conn.close()
    return df

def delete_news_from_db(news_ids):
    if not news_ids: return
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    placeholders = ', '.join('?' for _ in news_ids)
    c.execute(f"DELETE FROM saved_news WHERE id IN ({placeholders})", news_ids)
    conn.commit()
    conn.close()

# ì•± ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
init_db()

def load_seen_titles():
    if not os.path.exists(HISTORY_FILE):
        return set()
    with open(HISTORY_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f)

def save_seen_title(title):
    clean_title = title.replace("\n", " ")
    with open(HISTORY_FILE, "a", encoding="utf-8") as f:
        f.write(clean_title + "\n")

def format_date_kor(date_str):
    try:
        if not date_str: return "ì‹œê°„ ì •ë³´ ì—†ìŒ"
        dt = parsedate_to_datetime(date_str)
        KST = timezone(timedelta(hours=9))
        dt_kst = dt.astimezone(KST)
        return dt_kst.strftime("%Yë…„ %mì›” %dì¼ %H:%M")
    except:
        return date_str[:16]

def get_current_time_str():
    now = datetime.now()
    return now.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ")

def fetch_rss_feed(url):
    try:
        response = requests.get(url, timeout=10, verify=False)
        return feedparser.parse(response.content)
    except Exception as e:
        return None

# -------------------------------------------
# 2. í™”ë©´ êµ¬ì„± (UI)
# -------------------------------------------
st.set_page_config(page_title="ê¸°ì—… ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§", page_icon="ğŸ’»", layout="wide")

if 'selected_article_url' not in st.session_state:
    st.session_state['selected_article_url'] = None
if 'selected_article_title' not in st.session_state:
    st.session_state['selected_article_title'] = None

with st.sidebar:
    st.header("âš™ï¸ ëª¨ë‹ˆí„°ë§ ì„¤ì •")
    default_keywords = "ë¡¯ë°ë§ˆíŠ¸, ë¡¯ë°ì›°í‘¸ë“œ, [ë‹¨ë…]ë¡¯ë°, ë¡¯ë°ì¹ ì„±, ì„¸ë¸ì¼ë ˆë¸"
    user_input = st.text_area("í‚¤ì›Œë“œ ì…ë ¥ (ì½¤ë§ˆ êµ¬ë¶„)", value=default_keywords, height=100)
    
    KEYWORDS = [k.strip() for k in user_input.split(',') if k.strip()]
    
    st.divider()
    
    st.subheader("â±ï¸ ìë™ ì—…ë°ì´íŠ¸")
    auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ ì¼œê¸°", value=True)
    refresh_interval = st.slider("ì—…ë°ì´íŠ¸ ì£¼ê¸° (ë¶„)", 5, 60, 15)
    
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        if os.path.exists(HISTORY_FILE):
            os.remove(HISTORY_FILE)
            st.rerun()

st.title("ğŸ’» ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ (Gemini AI)")

# -------------------------------------------
# 3. ë©”ì¸ ë¡œì§
# -------------------------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ“¢ ë‰´ìŠ¤ ëª©ë¡", "ğŸ“ AI ìƒì„¸ ìš”ì•½", "ğŸ—„ï¸ ì €ì¥ì†Œ (DB)"])

# === [íƒ­ 1] ë‰´ìŠ¤ ëª©ë¡ ===
with tab1:
    status_container = st.container()
    
    seen_titles = load_seen_titles()
    grouped_news = {k: [] for k in KEYWORDS}
    new_news_count = 0 
    
    for keyword in KEYWORDS:
        clean_keyword = keyword.strip()
        search_query = clean_keyword + " when:1h"
        encoded_keyword = urllib.parse.quote(search_query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=ko&gl=KR&ceid=KR:ko"
        
        feed = fetch_rss_feed(rss_url)
        
        if not feed or not feed.entries:
            continue

        for entry in feed.entries:
            title = entry.title
            link = entry.link
            nice_date = format_date_kor(entry.get('published', ''))
            
            if clean_keyword not in title: continue
            
            grouped_news[clean_keyword].append({
                "title": title, "link": link, "date": nice_date
            })
            
            if title not in seen_titles:
                seen_titles.add(title)
                save_seen_title(title)
                new_news_count += 1

    current_time = get_current_time_str()
    if new_news_count > 0:
        status_container.success(f"ğŸ”¥ **ì—…ë°ì´íŠ¸ ì™„ë£Œ ({current_time})** : {new_news_count}ê±´ì˜ ìƒˆë¡œìš´ ë‰´ìŠ¤!")
        st.toast(f"{new_news_count}ê±´ì˜ ìƒˆ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤!", icon="ğŸ”¥")
    else:
        status_container.info(f"âœ… **ì—…ë°ì´íŠ¸ ì™„ë£Œ ({current_time})** : ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    btn_idx = 0 
    for keyword, items in grouped_news.items():
        if items: 
            with st.expander(f"ğŸ“‚ **{keyword}** ({len(items)}ê±´)", expanded=True):
                for item in items:
                    with st.container():
                        c1, c2, c3, c4 = st.columns([1.2, 3.5, 0.8, 0.8])
                        c1.markdown(f":orange[{item['date']}]")
                        c2.markdown(f"[{item['title']}]({item['link']})")
                        
                        if c3.button("ğŸ“ ìš”ì•½", key=f"btn_sum_{btn_idx}"):
                            st.session_state['selected_article_url'] = item['link']
                            st.session_state['selected_article_title'] = item['title']
                            st.toast("íƒ­ 2ë¡œ ì´ë™í•˜ì„¸ìš”!", icon="ğŸ‘‰")
                        
                        if c4.button("ğŸ’¾ ì €ì¥", key=f"btn_save_{btn_idx}"):
                            success = save_news_to_db(keyword, item['title'], item['link'], item['date'])
                            if success:
                                st.toast("ì €ì¥ì†Œ(DB)ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
                            else:
                                st.toast("ì´ë¯¸ ì €ì¥ëœ ë‰´ìŠ¤ì…ë‹ˆë‹¤.", icon="âš ï¸")
                                
                        btn_idx += 1
                    st.divider()

# === [íƒ­ 2] AI ìš”ì•½ (ìˆ˜ì •ë¨) ===
with tab2:
    st.header("ğŸ“ Gemini ê¸°ì‚¬ ìš”ì•½")
    selected_url = st.session_state['selected_article_url']
    
    if selected_url is None:
        st.info("ğŸ‘ˆ [ë‰´ìŠ¤ ëª©ë¡] íƒ­ì—ì„œ 'AI ìš”ì•½' ë²„íŠ¼ì„ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        st.subheader(f"{st.session_state['selected_article_title']}")
        st.markdown("---")
        
        # [ì¤‘ìš”] í•¨ìˆ˜ í˜¸ì¶œ ë¶€ë¶„
        with st.spinner("ğŸ”— ì‹¤ì œ ê¸°ì‚¬ ì£¼ì†Œë¥¼ ì°¾ëŠ” ì¤‘..."):
            final_url = get_final_url(selected_url)
        
        with st.spinner(f"Geminiê°€ ê¸°ì‚¬ë¥¼ ì½ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                config = Config()
                config.request_timeout = 10
                config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                config.request_kwargs = {'verify': False}
                
                article = Article(final_url, language='ko', config=config)
                article.download()
                article.parse()
                
                if article.top_image:
                    st.image(article.top_image, use_container_width=True)

                if len(article.text) < 50:
                    st.warning("âš ï¸ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë³´ì•ˆì´ ê°•í•œ ì–¸ë¡ ì‚¬ì´ê±°ë‚˜ ìœ ë£Œ ê¸°ì‚¬ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                    st.write(f"ë³€í™˜ëœ ë§í¬: {final_url}")
                else:
                    prompt = f"""
                    ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì½ê³  ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:
                    1. **í•œì¤„ ìš”ì•½**: ê¸°ì‚¬ì˜ í•µì‹¬ ì£¼ì œ
                    2. **ìƒì„¸ í¬ì¸íŠ¸**: ì¤‘ìš” ë‚´ìš© 3ê°€ì§€ (ê¸€ë¨¸ë¦¬ ê¸°í˜¸)
                    3. **ê°ì • ë¶„ì„**: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ì¤‘ í•˜ë‚˜
                    
                    [ê¸°ì‚¬ ë³¸ë¬¸]
                    {article.text[:3000]}
                    """
                    response = model.generate_content(prompt)
                    st.success(response.text)

                with st.expander("ì›ë³¸ ë³¸ë¬¸ ë³´ê¸°"):
                    st.write(article.text)
                    
            except Exception as e:
                st.error("ìš”ì•½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.caption(f"Error: {e}")

# === [íƒ­ 3] ì €ì¥ì†Œ (DB) ===
with tab3:
    st.header("ğŸ—„ï¸ ì €ì¥ëœ ë‰´ìŠ¤ ê´€ë¦¬")
    st.caption("ì˜êµ¬ ì €ì¥ëœ ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê±°ë‚˜ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    df = get_saved_news()
    
    if df.empty:
        st.info("ì•„ì§ ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë‰´ìŠ¤ ëª©ë¡' íƒ­ì—ì„œ 'ğŸ’¾ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")
    else:
        st.subheader(f"ì´ {len(df)}ê±´ì˜ ìŠ¤í¬ë©")
        
        df_display = df.copy()
        df_display['ì‚­ì œì„ íƒ'] = False
        df_display = df_display[['ì‚­ì œì„ íƒ', 'keyword', 'title', 'pub_date', 'saved_at', 'link', 'id']]
        
        edited_df = st.data_editor(
            df_display,
            column_config={
                "ì‚­ì œì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ", help="ì‚­ì œí•  í•­ëª© ì„ íƒ"),
                "keyword": "í‚¤ì›Œë“œ",
                "title": "ì œëª©",
                "pub_date": "ê¸°ì‚¬ ë‚ ì§œ",
                "saved_at": "ì €ì¥ ì¼ì‹œ",
                "link": st.column_config.LinkColumn("ë§í¬"),
                "id": None
            },
            hide_index=True,
            use_container_width=True
        )
        
        col1, col2 = st.columns([1, 4])
        
        with col1:
            if st.button("ğŸ—‘ï¸ ì„ íƒ í•­ëª© ì‚­ì œ", type="primary"):
                selected_ids = edited_df[edited_df['ì‚­ì œì„ íƒ'] == True]['id'].tolist()
                if selected_ids:
                    delete_news_from_db(selected_ids)
                    st.success(f"{len(selected_ids)}ê±´ ì‚­ì œ ì™„ë£Œ!")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.warning("ì‚­ì œí•  í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    
        with col2:
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€(CSV)ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"news_scrap_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )

if auto_refresh:
    time.sleep(refresh_interval * 60)
    st.rerun()
